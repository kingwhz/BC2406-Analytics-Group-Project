plot(density(copydt$LoanRatio))
## Need to remove the previous incomes and the loan
copydt = copydt[ ,c("ApplicantIncome","CoapplicantIncome","LoanAmount", "Loan_Amount_Term"):=NULL]
summary(copydt)
dim(copydt)
train_data = sample.split(Y=copydt$Loan_Status,SplitRatio = 0.7)
trainset = subset(copydt,train_data==T)
testset = subset(copydt, train_data==F)
summary(trainset$Loan_Status)
## Need to rebalance the trainset such that it is more "fair"
## Need to achieve 50% of each occurence. Set N to 2* amount of Y
balancetrain_data = ovun.sample(Loan_Status~., data=trainset, seed = 8, method ="over", N = 576 )$data
table(balancetrain_data$Loan_Status)
summary(balancetrain_data)
model1=glm(Loan_Status~.,data=balancetrain_data, family="binomial")
summary(model1)
OR = exp(coef(model1))
OR
CI = exp(confint(model1))
CI
## Keeping only signif variables using backwards elimination
model2=glm(Loan_Status~Married+Dependents+Credit_Score+Property_Area,data=balancetrain_data,family="binomial")
summary(model2)
model3=glm(Loan_Status~Married+Credit_Score+Property_Area,data=balancetrain_data, family="binomial")
summary(model3)
model4 =glm(Loan_Status~Credit_Score+Married,data=balancetrain_data, family="binomial")
summary(model4)
## Checking for the AIC values
model_list = c(AIC(model1), AIC(model2), AIC(model3),AIC(model4))
AIC(model1)
AIC(model2)
AIC(model3)
AIC(model4)
## Lowed AIC is best model
min(model_list)
levels(balancetrain_data$Loan_Status)
## Accuracy of Training on trainset
prob = predict(model2, type = 'response')
classifier = ifelse(prob>0.5, "N", "Y")
classifier=as.factor(classifier)
confusionMatrix(classifier,balancetrain_data$Loan_Status,positive = 'Y')
## Testing out on the testset with log model trained on balanced data
test_prob = predict(model2, newdata=testset, type="response")
test_classifier = ifelse(test_prob>0.5,"N","Y")
test_classifier = as.factor(test_classifier)
confusionMatrix(test_classifier,testset$Loan_Status,positive = 'Y')
log_model_acc = mean(test_classifier == testset$Loan_Status) * 100
log_model_acc
## Do Cart on balanced Data
bcart = rpart(Loan_Status ~. , data = balancetrain_data, method="class",control = rpart.control(cp=0))
printcp(bcart)
plotcp(bcart)
rpart.plot(bcart, nn = T, main ="Maximal Balance CART")
## Pruning the tree
## Acknowledgements to Professor Neumann of BC2406 for the pruning code.
cverrorcap = bcart$cptable[which.min(bcart$cptable[,"xerror"]),"xerror"] + bcart$cptable[which.min(bcart$cptable[,"xerror"]),"xstd"]
i = 1; j=4
while (bcart$cptable[i,j] > cverrorcap) {
i = i+1
}
optimal_cp = ifelse(i > 1, sqrt(bcart$cptable[i,1] * bcart$cptable[i-1,1]),1)
optimal_cp
bcart2 = prune(bcart, cp = optimal_cp)
rpart.plot(bcart2,nn=T,main="Pruned Tree")
bcart2 = prune(bcart, cp = optimal_cp, minsplit = 20)
rpart.plot(bcart2,nn=T,main="Pruned Tree")
rpart.plot(bcart2,nn=T,main="New Pruned Tree")
bcart2 = prune(bcart, cp = optimal_cp, minsplit = 10)
rpart.plot(bcart2,nn=T,main="New Pruned Tree")
rpart.plot(bcart2,nn=T,main="Newer Pruned Tree")
bcart2 = prune(bcart, cp = optimal_cp, minsplit = 1)
rpart.plot(bcart2,nn=T,main="Newer Pruned Tree")
## Installing all the necessary packages
install.packages("stringr")
install.packages("stringr")
library(stringr)
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining")
df1 = read.csv("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining/Data/jnlactive.csv")
df2 = str_replace_all(df1$Full.Title,"[^[:alnum:]]", " ")
## Installing all the necessary packages
install.packages("stringr")
install.packages("stringr")
library(stringr)
library(stringr)
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining")
df1 = read.csv("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining/Data/jnlactive.csv")
df1
view(df1)
## Counting characters in string
str_length("fruit")
## Count words
str_count("i like peanuts", "I")
## Count words
str_count("I like peanuts", "I")
## Count words
str_count("i like peanuts", "I")
## Count words
str_count("i like peanuts", "I")
## Converting to upper case
str_to_upper("hello")
## Searching pattern and returning boolean
str_detect("homo", "omo")
## replacing string
str_replace("fruit", "i", 1)
## replacing string
str_replace("fruit", "i", "1")
## Concatenating words
str_c("a", "girl", sep = "+")
## replacing string
str_replace_all("fruit", "i", "1")
## replacing string
str_replace("fruit", "i", "1")
str_replace_all("helleee", "a")
str_replace_all("helleee", "e","a")
str_to_lower("PARACETAMOL 500MG")
str_to_lower("PARACETAMOL 500MG") == "paracetamol 500mg"
str = "PARACETAMOL 500MG"
str_replace_all(str, "[0-9", "")
str_replace_all(str, "[0-9]", "")
str = "PARACETAMOL 500MG"
str_replace_all(str, "[0-9]", "")
str_to_lower("PARACETAMOL 500MG")
str_replace_all(str, "[0-9]", "").str_to_lower
## Question 1: What is the distribution of words1 in a journal title
df2
install.packages("stringr")
library(stringr)
install.packages("stringr")
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining")
df1 = read.csv("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining/Data/jnlactive.csv")
df1
view(df1)
## Counting characters in string
str_length("fruit")
## Count words
str_count("i like peanuts", "I")
## Converting to upper case
str_to_upper("hello")
## Searching pattern and returning boolean
str_detect("homo", "omo")
## replacing string
str_replace("fruit", "i", "1")
str_replace_all("helleee", "e","a")
## Concatenating words
str_c("a", "girl", sep = "+")
str_to_lower("PARACETAMOL 500MG")
str = "PARACETAMOL 500MG"
str_replace_all(str, "[0-9]", "")
## Basic Cleaning of the strings in the CSV
df2 = str_replace_all(df1$Full.Title,"[^[:alnum:]]", " ")
## Question 1: What is the distribution of words1 in a journal title
df2
distribution_table=sort(table(unlist(strsplit(df2, " "))),decreasing = TRUE)
distribution_table
## Prof Solution
df2$title.fix
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining")
df1 = read.csv("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining/Data/jnlactive.csv")
df1
view(df1)
df1$Full.Title = str_remove_all(df1$Full.Title, pattern = ["[,-]")
df1$Full.Title = str_remove_all(df1$Full.Title, pattern = "[,-]")
df1$Full.Title = str_remove_all(df1$Full.Title, pattern = "[,-]")
## -> Counting Words
str_count(df1$Full.Title, "")+1
## -> Counting Words
max(str_count(df1$Full.Title, "")+1)
## -> Counting Words
max(str_count(df1$Full.Title, " ")+1)
## Question 2: What is the longest number of words in a journal title
longest_header = df2[order(-nchar(df2))][1]
longest_header
print(longest_header)
## physical count was 15 words, but R shows 14?
str_count(longest_header ,"\\W+")
distribution_table=sort(table(unlist(strsplit(df2, " "))),decreasing = TRUE)
distribution_table
## Option 1:
wordcount = str_count(df1$Full.Title, " ")+1
table(wordcount)
## Option 2:
titles_list = str_split(df1$Full.Title, pattern = " ")
words_per_title = sapply(titles_list, length)
words_per_title
tables(words_per_title)
## Option 1:
wordcount = str_count(df1$Full.Title, " ")+1
table(wordcount)
## Option 2:
titles_list = str_split(df1$Full.Title, pattern = " ")
words_per_title = sapply(titles_list, length)
## Option 2:
## Split title by words
titles_list = str_split(df1$Full.Title, pattern = " ")
## Number of words per title
words_per_title = sapply(titles_list, length)
df1$Full.Title = str_remove_all(df1$Full.Title, pattern = "[,-]")
## -> Counting Words
max(str_count(df1$Full.Title, " ")+1)
## Number of words per title
words_per_title = sapply(titles_list, length)
##Question 3: What is the name of the journal with the longest number of words in title?
nchar(longest_header)
longest_header
## -> Counting Words
max(str_count(df1$Full.Title, " ")+1)
## Prof Solution
ma_title_list = titles_list[which(words_per_title == 19)]
## Prof Solution
max_title_list = titles_list[which(words_per_title == 19)]
##Question 3: What is the name of the journal with the longest number of words in title?
nchar(longest_header)
max_title_list
##Question 3: What is the name of the journal with the longest number of words in title?
nchar(longest_header)
longest_header
## Prof solution
## Get Vector of words in titles
title_words = unlist(titles_list)
title_words
##Question 5:
## Getting Unique Words
unique_words = unique(title_words)
unique_words
length(unique_words)
## Table with word frequencies
word_freq = table(title_words)
word_freq
newerdf$glimepiride_No
lclass <- sapply(newerdf, class) == "logical"
lcols <- names(lclass)[which(lclass==TRUE)]
newerdf[, (lcols):= lapply(.SD, as.numeric), .SDcols = lcols]
newerdf[, (lcols):= lapply(.SD, factor), .SDcols = lcols]
sapply(newer_df, class)
## Need to convert "logical" to "factor" for further analysis
newerdf <- newdf %>% mutate_if(is.logical, as.factor)
sapply(newerdf, class)
newerdf$`age_[40-50)`
class(newerdf$`age_[40-50)`)
lclass <- sapply(newerdf, class) == "integer"
lcols <- names(lclass)[which(lclass==TRUE)]
newerdf[, (lcols):= lapply(.SD, as.numeric), .SDcols = lcols]
newerdf[, (lcols):= lapply(.SD, factor), .SDcols = lcols]
class(newerdf$`age_[40-50)`)
library(readtext)
## Testing this shit out on VS Code
## Install packages
install.packages("readtext")
install.packages("quanteda")
library(quanteda)
library(readtext)
library(quanteda)
library(readtext)
library(quanteda)
## Example
corp = corpus("A lovely cute cat was jumping towards me, I was not afraid and jumped too")
corp
## Token
toekn_corp = tokens(corp)
unlist(toekn_corp)
## Token
token_corp = tokens(corp)
unlist(token_corp)
## Removing Stopwords
token_corp = tokens_remove(token_corp)
unlist(token_corp)
## Stemming
token_corp = tokens_wordstem(token_corp)
token_corp
## Removing punctuations
token_corp = tokens_remove(token_corp, stopwords("en"))
library(ggplot2)
library(reshape2)
library(quanteda.textplots)
## BC2406 Week 10 Attempt 1
## Ng Jun Long
## U2110010D
install.packages("quanteda.textplots")
library(quanteda.textplots)
## Question 7
quanteda_options("threads" = 4)
## Importing text files to a folder
ndr_data = readtext("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Unit 10 - Strings and Text Mining/Data/NDR", docvarsfrom = "filenames", docvarnames = c("Year", "Person", "Speech"), dvsep = "_", encoding = "UTF-8")
## Create a corpus
ndr_corpus = corpus(ndr_data)
summary(ndr_corpus)
## Metadata attributes to subset corpus
ndr_token = tokens(ndr_corpus)
nrd_tokens1 = tokens(ndr_corpus, remove_punct = T, remove_numbers = T)
sum(ntoken((ndr_token)))
sum(ntoken((ndr_tokens1)))
nrd_tokens1 = tokens(ndr_corpus, remove_punct = T, remove_numbers = T)
sum(ntoken((ndr_token)))
sum(ntoken((ndr_tokens1)))
ndr_tokens1 = tokens(ndr_corpus, remove_punct = T, remove_numbers = T)
sum(ntoken((ndr_token)))
sum(ntoken((ndr_tokens1)))
ndr_tokens2 = tokens_wordstem(ndr_tokens1)
ndr_tokens2 = tokens_wordstem(ndr_tokens1)
## Converting class type integer to factor
lclass <- sapply(newerdf, class) == "integer"
lcols <- names(lclass)[which(lclass==TRUE)]
newerdf[, (lcols):= lapply(.SD, as.numeric), .SDcols = lcols]
newerdf[, (lcols):= lapply(.SD, factor), .SDcols = lcols]
sapply(newerdf, class)
##Setting seed
set.seed(2004)
testdf
dt1 = rpart(readmitted ~., data = testdf, method ="class",control =rpart.control(minsplit=20,cp=0))
dt1
printcp(dt1)
colnames(testdf)
testdf$`age_[70-80)` = test$Age70-80
testdf$`age_[70-80)` = testdf$Age70-80
setnames(testdf,"age_[70-80)", "age[70-80]" )
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
colnames(testdf)
colnames(testdf)[colnames(testdf)]
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")] = c("Age40-50","Age50-60","Age60-70","Age70-80","Age80-90")
colnames(testdf)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
setnames(testdf,"age_[70-80)", "age[70-80]")
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")] = c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
setnames(testdf,"age_[70-80)", "age[70-80]")
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset")
newdf = fread('/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset/secondreadmissioncleaned_data.csv', na.strings = c("NA", "missing", "N/A", "", "m", "M", "na", "."))
## Data exploration
summary(newdf)
colnames(newdf)
ncol(newdf)
sapply(newdf, class)
## Need to convert "logical" to "factor" for further analysis
newerdf <- newdf %>% mutate_if(is.logical, as.factor)
sapply(newerdf, class)
## Checking for duplicated values in columns that are supposed to be unique
newerdf$number_outpatient
newerdf$number_diagnoses
newerdf$`payer_code_?`
newerdf$glimepiride_No
## Converting class type integer to factor
lclass <- sapply(newerdf, class) == "integer"
lcols <- names(lclass)[which(lclass==TRUE)]
newerdf[, (lcols):= lapply(.SD, as.numeric), .SDcols = lcols]
newerdf[, (lcols):= lapply(.SD, factor), .SDcols = lcols]
sapply(newerdf, class)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
setnames(testdf,"age_[70-80)", "age[70-80]")
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")] = c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
colnames(testdf)
##Setting seed
set.seed(2004)
testdf
dt1 = rpart(readmitted ~., data = testdf, method ="class",control =rpart.control(minsplit=20,cp=0))
dt1
printcp(dt1)
plotcp(dt1,main="unpruned tree")
## Automate the pruning process
dt2 = data.table(dt1$cptable)
colnames(testdf)
## Testing this shit out on VS Code
## Install packages
install.packages("readtext")
install.packages("quanteda")
library(data.table)
library(dplyr)
library(rpart)
library(readtext)
library(quanteda)
library(rpart.plot)
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset")
newdf = fread('/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset/secondreadmissioncleaned_data.csv', na.strings = c("NA", "missing", "N/A", "", "m", "M", "na", "."))
## Data exploration
summary(newdf)
colnames(newdf)
ncol(newdf)
sapply(newdf, class)
## Need to convert "logical" to "factor" for further analysis
newerdf <- newdf %>% mutate_if(is.logical, as.factor)
sapply(newerdf, class)
## Checking for duplicated values in columns that are supposed to be unique
newerdf$number_outpatient
newerdf$number_diagnoses
newerdf$`payer_code_?`
newerdf$glimepiride_No
## Converting class type integer to factor
lclass <- sapply(newerdf, class) == "integer"
lcols <- names(lclass)[which(lclass==TRUE)]
newerdf[, (lcols):= lapply(.SD, as.numeric), .SDcols = lcols]
newerdf[, (lcols):= lapply(.SD, factor), .SDcols = lcols]
sapply(newerdf, class)
install.packages("readtext")
install.packages("quanteda")
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset")
newdf = fread('/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset/secondreadmissioncleaned_data.csv', na.strings = c("NA", "missing", "N/A", "", "m", "M", "na", "."))
## Data exploration
summary(newdf)
colnames(newdf)
ncol(newdf)
sapply(newdf, class)
## Need to convert "logical" to "factor" for further analysis
newerdf <- newdf %>% mutate_if(is.logical, as.factor)
sapply(newerdf, class)
## Checking for duplicated values in columns that are supposed to be unique
newerdf$number_outpatient
newerdf$number_diagnoses
newerdf$`payer_code_?`
newerdf$glimepiride_No
## Converting class type integer to factor
lclass <- sapply(newerdf, class) == "integer"
lcols <- names(lclass)[which(lclass==TRUE)]
newerdf[, (lcols):= lapply(.SD, as.numeric), .SDcols = lcols]
newerdf[, (lcols):= lapply(.SD, factor), .SDcols = lcols]
sapply(newerdf, class)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
setnames(testdf,"age_[70-80)", "age[70-80]")
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")]
= c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")]= c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")]= c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
setwd("/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset")
newdf = fread('/Users/junlongng/Desktop/NTU/Year 2/Semester 1/BC2406 Analytics 1/Group Project/Data Sets/Dataset/secondreadmissioncleaned_data.csv', na.strings = c("NA", "missing", "N/A", "", "m", "M", "na", "."))
## Data exploration
summary(newdf)
colnames(newdf)
ncol(newdf)
sapply(newdf, class)
## Need to convert "logical" to "factor" for further analysis
newerdf <- newdf %>% mutate_if(is.logical, as.factor)
sapply(newerdf, class)
## Checking for duplicated values in columns that are supposed to be unique
newerdf$number_outpatient
newerdf$number_diagnoses
newerdf$`payer_code_?`
newerdf$glimepiride_No
## Converting class type integer to factor
lclass <- sapply(newerdf, class) == "integer"
lcols <- names(lclass)[which(lclass==TRUE)]
newerdf[, (lcols):= lapply(.SD, as.numeric), .SDcols = lcols]
newerdf[, (lcols):= lapply(.SD, factor), .SDcols = lcols]
sapply(newerdf, class)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")]= c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
colnames(testdf)
testdf$V1
## Seems to be ID of person.
testdf = testdf[,c[-1]]
## Seems to be ID of person.
testdf = testdf[,c(-1)]
testdf
colnames(testdf)
## Seems to be ID of person. Dropping the column
testdf = testdf[,c(-1)]
## Taking a closer look into V1
testdf$V1
## Seems to be ID of person. Dropping the column
testdf = testdf[,c(-1)]
##Setting seed
set.seed(2004)
testdf
dt1 = rpart(readmitted ~., data = testdf, method ="class",control =rpart.control(minsplit=20,cp=0))
dt1
ncol(testdf)
## Seems to be ID of person. Dropping the column
testdf = testdf[,c(-1)]
ncol(testdf)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")]= c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
colnames(testdf)
## Taking a closer look into V1
testdf$V1
## Seems to be ID of person. Dropping the column
cleaning_df = testdf[,c(-1)]
ncol(testdf)
ncol(cleaning_df)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
colnames(testdf)[colnames(testdf) %in% c("age_[40-50)","age_[50-60)","age_[60-70)","age_[70-80)","age_[80-90)")]= c("Age40_50","Age50_60","Age60_70","Age70_80","Age80_90")
colnames(testdf)
## Taking a closer look into V1
testdf$V1
## Seems to be ID of person. Dropping the column
cleaning_df = testdf[,c(-1)]
ncol(cleaning_df)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
ncol(cleaning_df)
ncol(testdf)
## Changing True values to be 1, False values to be 0 for all columns that is needed
## Cheated by changing the values in excel
testdf = newerdf
ncol(testdf)
ncol(cleaning_df)
